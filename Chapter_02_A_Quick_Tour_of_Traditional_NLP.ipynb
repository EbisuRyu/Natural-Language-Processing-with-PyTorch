{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‹ Xin chÃ o má»i ngÆ°á»i! MÃ¬nh lÃ  Long, vÃ  Ä‘Ã¢y lÃ  bÃ i viáº¿t thá»© hai trong loáº¡t bÃ i chia sáº» nhá»¯ng kiáº¿n thá»©c mÃ  mÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c tá»« cuá»‘n sÃ¡ch *Natural Language Processing with PyTorch*. Hy vá»ng nhá»¯ng chia sáº» nÃ y sáº½ mang láº¡i giÃ¡ trá»‹ há»¯u Ã­ch cho cÃ¡c báº¡n. HÃ´m nay, chÃºng ta sáº½ cÃ¹ng khÃ¡m phÃ¡ chÆ°Æ¡ng tiáº¿p theo: **Chapter 2: A Quick Tour of Traditional NLP**. ğŸ“š  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong **Computational Study of Human Language**, cÃ³ hai lÄ©nh vá»±c chÃ­nh mÃ  chÃºng ta cáº§n lÆ°u Ã½:\n",
    "\n",
    "- **Natural Language Processing (NLP)** ğŸ§ : Má»¥c tiÃªu cá»§a NLP lÃ  phÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p giáº£i quyáº¿t nhá»¯ng váº¥n Ä‘á» thá»±c tiá»…n liÃªn quan Ä‘áº¿n ngÃ´n ngá»¯, bao gá»“m: **information extraction** ğŸ“„, **automatic speech recognition** ğŸ¤, **machine translation** ğŸŒ, **sentiment analysis** ğŸ’¬, **question answering** â“, vÃ  **summarization** âœ‚ï¸. NLP hÆ°á»›ng Ä‘áº¿n viá»‡c mang láº¡i nhá»¯ng giáº£i phÃ¡p thá»±c tiá»…n trong tháº¿ giá»›i sá»‘ hÃ³a hiá»‡n Ä‘áº¡i.  \n",
    "- **Computational Linguistics (CL)** ğŸ”: CL táº­p trung vÃ o viá»‡c phÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ­nh toÃ¡n Ä‘á»ƒ khÃ¡m phÃ¡ vÃ  hiá»ƒu rÃµ hÆ¡n vá» cÃ¡c Ä‘áº·c Ä‘iá»ƒm vÃ  cáº¥u trÃºc cá»§a ngÃ´n ngá»¯ con ngÆ°á»i.\n",
    "\n",
    "ThÃ´ng thÆ°á»ng, hai lÄ©nh vá»±c nÃ y cÃ³ sá»± giao thoa máº¡nh máº½, khi cÃ¡c phÆ°Æ¡ng phÃ¡p tá»« CL Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ o NLP vÃ  ngÆ°á»£c láº¡i. Tuy nhiÃªn, trong cuá»‘n sÃ¡ch nÃ y, tÃ¡c giáº£ sáº½ táº­p trung chá»§ yáº¿u vÃ o **NLP**, Ä‘á»“ng thá»i sáº½ mÆ°á»£n má»™t sá»‘ Ã½ tÆ°á»Ÿng tá»« **CL** khi cáº§n thiáº¿t. Ná»™i dung chÃ­nh cá»§a sÃ¡ch lÃ  khÃ¡m phÃ¡ cÃ¡c **neural network methods** ğŸ¤– trong NLP, Ä‘á»“ng thá»i nhÃ¬n láº¡i nhá»¯ng khÃ¡i niá»‡m vÃ  phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng trong lÄ©nh vá»±c nÃ y.\n",
    "\n",
    "ChÆ°Æ¡ng nÃ y sáº½ giÃºp chÃºng ta cÃ³ cÃ¡i nhÃ¬n tá»•ng quan vá» cÃ¡c phÆ°Æ¡ng phÃ¡p NLP truyá»n thá»‘ng, táº¡o ná»n táº£ng vá»¯ng cháº¯c trÆ°á»›c khi chuyá»ƒn sang cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n Ä‘áº¡i hÆ¡n.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Corpora, Tokens, and Types**ğŸ“šğŸ’¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Corpus** ğŸ“š: Trong NLP, báº¥t ká»³ phÆ°Æ¡ng phÃ¡p nÃ o, dÃ¹ cá»• Ä‘iá»ƒn hay hiá»‡n Ä‘áº¡i, Ä‘á»u báº¯t Ä‘áº§u tá»« má»™t bá»™ dá»¯ liá»‡u vÄƒn báº£n, hay cÃ²n gá»i lÃ  **corpus**. Má»™t **corpus** thÆ°á»ng chá»©a cÃ¡c **raw text** âœï¸ vÃ  báº¥t ká»³ **metadata** ğŸ“ nÃ o liÃªn quan Ä‘áº¿n vÄƒn báº£n Ä‘Ã³.  \n",
    "    - **Raw text**: LÃ  chuá»—i kÃ½ tá»± thÃ´, nhÆ°ng thÆ°á»ng sáº½ hiá»‡u quáº£ hÆ¡n khi chia cÃ¡c chuá»—i kÃ½ tá»± nÃ y thÃ nh nhá»¯ng Ä‘Æ¡n vá»‹ nhá» hÆ¡n, gá»i lÃ  **tokens** ğŸ” .\n",
    "    - **Metadata**: LÃ  báº¥t ká»³ thÃ´ng tin bá»• sung nÃ o Ä‘Æ°á»£c gÃ¡n vÃ o Ä‘oáº¡n vÄƒn báº£n, vÃ­ dá»¥ nhÆ° **labels** ğŸ”– (nhÃ£n phÃ¢n loáº¡i) hoáº·c **timestamps** â±ï¸ (dáº¥u thá»i gian).\n",
    "  \n",
    "- Trong há»c mÃ¡y, Ä‘oáº¡n vÄƒn báº£n kÃ¨m theo metadata cá»§a nÃ³ Ä‘Æ°á»£c gá»i lÃ  má»™t **instance** ğŸ“ hoáº·c **data point**. **Corpus** chÃ­nh lÃ  má»™t táº­p há»£p cÃ¡c **instances**, Ä‘Æ°á»£c gá»i chung lÃ  **dataset** ğŸ“Š.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./images/chapter_02_figure_01.png\" alt=\"image\" />\n",
    "</div>\n",
    "\n",
    "- **Tokenization** ğŸ”„: LÃ  quÃ¡ trÃ¬nh phÃ¢n tÃ¡ch Ä‘oáº¡n vÄƒn báº£n thÃ nh cÃ¡c **tokens** (Ä‘Æ¡n vá»‹ ngÃ´n ngá»¯ nhá» nháº¥t cÃ³ Ã½ nghÄ©a trong phÃ¢n tÃ­ch).\n",
    "  \n",
    "- **Types** ğŸ” : LÃ  cÃ¡c token duy nháº¥t trong **corpus**.  \n",
    "    - **Set of all Types**: LÃ  **Vocabulary** ğŸ“– hoáº·c **Corpus** ğŸ“š.\n",
    "    - CÃ¡c tá»« cÃ³ thá»ƒ Ä‘Æ°á»£c chia thÃ nh hai loáº¡i chÃ­nh: **content words** ğŸ“ (tá»« mang nghÄ©a chÃ­nh) vÃ  **stopwords** ğŸš« (tá»« dá»«ng).  \n",
    "    - **Stopwords**: Bao gá»“m nhá»¯ng tá»« nhÆ° máº¡o tá»« vÃ  giá»›i tá»«, chá»§ yáº¿u phá»¥c vá»¥ má»¥c Ä‘Ã­ch ngá»¯ phÃ¡p thay vÃ¬ mang Ã½ nghÄ©a cá»¥ thá»ƒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', ',', 'do', \"n't\", 'slap', 'the', 'green', 'witch']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = \"Mary, don't slap the green witch\"\n",
    "print([str(token) for token in nlp(text.lower())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Snow', 'White', 'and', 'the', 'Seven', 'Degrees', '#MakeAMovieCold', '@midnight', ':-)']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tweet = \"\"\"\n",
    "    Snow White and the Seven Degrees\n",
    "    #MakeAMovieCold@midnight:-) \n",
    "\"\"\"\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "print(tokenizer.tokenize(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Unigrams, Bigrams, Trigrams, ..., N-grams** ğŸ” ğŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP), **n-grams** lÃ  má»™t khÃ¡i niá»‡m quan trá»ng dÃ¹ng Ä‘á»ƒ mÃ´ táº£ chuá»—i cÃ¡c Ä‘Æ¡n vá»‹ liÃªn tiáº¿p trong vÄƒn báº£n. N-grams cÃ³ thá»ƒ lÃ  cÃ¡c tá»«, kÃ½ tá»±, hoáº·c cÃ¡c Ä‘Æ¡n vá»‹ ngÃ´n ngá»¯ khÃ¡c, giÃºp mÃ´ hÃ¬nh náº¯m báº¯t Ä‘Æ°á»£c cáº¥u trÃºc vÃ  ngá»¯ nghÄ©a cá»§a vÄƒn báº£n.\n",
    "\n",
    "- **Unigrams** ğŸ…¾ï¸: LÃ  cÃ¡c Ä‘Æ¡n vá»‹ riÃªng láº» (tá»« Ä‘Æ¡n) trong vÄƒn báº£n. \n",
    "    - VÃ­ dá»¥, trong cÃ¢u `\"Há»c NLP tháº­t thÃº vá»‹\"`, cÃ¡c unigrams sáº½ lÃ : `[\"Há»c\", \"NLP\", \"tháº­t\", \"thÃº\", \"vá»‹\"]`.\n",
    "  \n",
    "- **Bigrams** ğŸ”: LÃ  cÃ¡c cáº·p tá»« liÃªn tiáº¿p. \n",
    "    - VÃ­ dá»¥, trong cÃ¢u `\"Há»c NLP tháº­t thÃº vá»‹\"`, cÃ¡c bigrams sáº½ lÃ : `[\"Há»c NLP\", \"NLP tháº­t\", \"tháº­t thÃº\", \"thÃº vá»‹\"]`.\n",
    "  \n",
    "- **Trigrams** ğŸ”º: LÃ  cÃ¡c nhÃ³m ba tá»« liÃªn tiáº¿p. \n",
    "    - VÃ­ dá»¥, tá»« cÃ¢u `\"Há»c NLP tháº­t thÃº vá»‹\"`, trigrams sáº½ lÃ : `[\"Há»c NLP tháº­t\", \"NLP tháº­t thÃº\", \"tháº­t thÃº vá»‹\"]`.\n",
    "  \n",
    "- **N-grams** ğŸ§©: LÃ  chuá»—i cÃ¡c tá»« cÃ³ Ä‘á»™ dÃ i **n** tÃ¹y Ã½. N-grams cÃ³ thá»ƒ bao gá»“m unigrams, bigrams, trigrams, vÃ  cÃ¡c tá»• há»£p cÃ³ Ä‘á»™ dÃ i cao hÆ¡n tÃ¹y thuá»™c vÃ o má»¥c tiÃªu cá»§a mÃ´ hÃ¬nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mary', ',', \"n't\"], [',', \"n't\", 'slap'], [\"n't\", 'slap', 'green'], ['slap', 'green', 'witch'], ['green', 'witch', '.']]\n"
     ]
    }
   ],
   "source": [
    "def n_gram(text, n):\n",
    "    '''\n",
    "    takes tokens or text, returns a list of n-grams\n",
    "    '''\n",
    "    return [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "\n",
    "cleaned = ['mary', ',', \"n't\", 'slap', 'green', 'witch', '.']\n",
    "print(n_gram(cleaned, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lemmas and Stems**ğŸ”¤ğŸŒ¿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong NLP, viá»‡c hiá»ƒu vÃ  xá»­ lÃ½ cÃ¡c **lemmas** vÃ  **stems** lÃ  ráº¥t quan trá»ng khi phÃ¢n tÃ­ch ngÃ´n ngá»¯. Cáº£ hai khÃ¡i niá»‡m nÃ y giÃºp giáº£m thiá»ƒu sá»± phá»©c táº¡p cá»§a vÄƒn báº£n báº±ng cÃ¡ch biáº¿n cÃ¡c tá»« phá»©c táº¡p thÃ nh dáº¡ng chuáº©n cá»§a chÃºng.\n",
    "\n",
    "- **Lemmas** âœ¨: LÃ  dáº¡ng chuáº©n cá»§a má»™t tá»«, Ä‘Æ°á»£c tÃ¬m tháº¥y trong tá»« Ä‘iá»ƒn. **Lemmatization** lÃ  quÃ¡ trÃ¬nh biáº¿n Ä‘á»•i má»™t tá»« vá» dáº¡ng gá»‘c cá»§a nÃ³, Ä‘áº£m báº£o nghÄ©a cá»§a tá»« khÃ´ng bá»‹ thay Ä‘á»•i. VÃ­ dá»¥, tá»« \"better\" sáº½ Ä‘Æ°á»£c chuyá»ƒn thÃ nh \"good\", hoáº·c \"running\" sáº½ trá»Ÿ thÃ nh \"run\". QuÃ¡ trÃ¬nh nÃ y yÃªu cáº§u hiá»ƒu rÃµ ngá»¯ cáº£nh vÃ  cÃº phÃ¡p cá»§a cÃ¢u. Má»™t sá»‘ trÆ°á»ng há»£p chuyá»ƒn Ä‘á»•i tá»« thÃ nh **lemmas** cÃ³ thá»ƒ hiá»‡u quáº£ vÃ¬ giÃºp giáº£m sá»‘ lÆ°á»£ng tá»« trong **vocabulary**, Ä‘á»“ng thá»i giá»¯ cho chiá»u cá»§a vector biá»ƒu diá»…n khÃ´ng quÃ¡ cao.\n",
    "\n",
    "- **Stems** ğŸŒ±: LÃ  dáº¡ng rÃºt gá»n cá»§a má»™t tá»«, Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch loáº¡i bá» cÃ¡c háº­u tá»‘ vÃ  tiá»n tá»‘. LÃ  phÆ°Æ¡ng phÃ¡p lemmatization Ä‘Æ¡n giáº£n hÆ¡n. NÃ³ sá»­ dá»¥ng cÃ¡c quy táº¯c thá»§ cÃ´ng Ä‘á»ƒ loáº¡i bá» cÃ¡c háº­u tá»‘ cá»§a tá»«, giÃºp rÃºt gá»n tá»« vá» má»™t dáº¡ng chung gá»i lÃ  stems. Tuy nhiÃªn, **stemmer** cÃ³ thá»ƒ khÃ´ng táº¡o ra tá»« chuáº©n nhÆ° **lemmatizer**. VÃ­ dá»¥, tá»« \"running\" cÃ³ thá»ƒ Ä‘Æ°á»£c rÃºt gá»n thÃ nh \"run\", nhÆ°ng má»™t sá»‘ tá»« nhÆ° \"better\" cÃ³ thá»ƒ trá»Ÿ thÃ nh \"bett\". **Stemming** thÆ°á»ng khÃ´ng quan tÃ¢m Ä‘áº¿n ngá»¯ cáº£nh vÃ  cÃ³ thá»ƒ dáº«n Ä‘áº¿n cÃ¡c káº¿t quáº£ khÃ´ng chÃ­nh xÃ¡c. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he -> he\n",
      "was -> be\n",
      "running -> run\n",
      "late -> late\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"he was running late\")\n",
    "for token in doc:\n",
    "    print(f\"{token} -> {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Categorizing Sentences and Documents** ğŸ“„ğŸ”–\n",
    "\n",
    "CÃ¡c tÃ¡c vá»¥ **categorizing** hay **classifying documents** lÃ  má»™t trong nhá»¯ng á»©ng dá»¥ng sá»›m nháº¥t cá»§a NLP. CÃ¡c biá»ƒu diá»…n nhÆ° **TF** hoáº·c **TF-IDF** ráº¥t hiá»‡u quáº£ Ä‘á»‘i vá»›i cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i cÃ¡c chuá»—i vÄƒn báº£n dÃ i, nhÆ° tÃ i liá»‡u vÃ  nhiá»u cÃ¢u."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorizing Words: POS Tagging** ğŸ·ï¸ğŸ” \n",
    "\n",
    "**POS tagging** (Part-of-Speech tagging) lÃ  quÃ¡ trÃ¬nh phÃ¢n loáº¡i tá»« trong cÃ¢u theo cÃ¡c loáº¡i tá»« ngá»¯ phÃ¡p nhÆ° danh tá»«, Ä‘á»™ng tá»«, tÃ­nh tá»«, tráº¡ng tá»«, v.v. ÄÃ¢y lÃ  má»™t bÆ°á»›c quan trá»ng trong viá»‡c hiá»ƒu ngá»¯ nghÄ©a cá»§a vÄƒn báº£n vÃ  giÃºp há»‡ thá»‘ng NLP xá»­ lÃ½ vÄƒn báº£n hiá»‡u quáº£ hÆ¡n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marry -> PROPN\n",
      "slapped -> VERB\n",
      "the -> DET\n",
      "green -> PROPN\n",
      "witch -> PROPN\n",
      ". -> PUNCT\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"Marry slapped the green witch.\")\n",
    "for token in doc:\n",
    "    print(f\"{token} -> {token.pos_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorizing Spans: Chunking and Named Entity Recognition** ğŸ§‘â€ğŸ’»ğŸ”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThÃ´ng thÆ°á»ng, chÃºng ta cáº§n gÃ¡n nhÃ£n cho chuá»—i liÃªn tiáº¿p cÃ¡c **tokens**, quÃ¡ trÃ¬nh nÃ y gá»i lÃ  **chunking** ğŸ§© hoáº·c **shallow parsing** ğŸ”. Má»¥c tiÃªu cá»§a chunking lÃ  táº¡o ra cÃ¡c Ä‘Æ¡n vá»‹ ngá»¯ nghÄ©a cao cáº¥p hÆ¡n, Ä‘Æ°á»£c cáº¥u thÃ nh tá»« cÃ¡c thÃ nh pháº§n ngá»¯ phÃ¡p cÆ¡ báº£n nhÆ° danh tá»«, Ä‘á»™ng tá»«, tÃ­nh tá»«, v.v. Náº¿u khÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh **shallow parsing** ğŸ”, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c **biá»ƒu thá»©c chÃ­nh quy** (regular expressions) ğŸ“œ trÃªn cÃ¡c nhÃ£n **part-of-speech tags** Ä‘á»ƒ xáº¥p xá»‰ quÃ¡ trÃ¬nh phÃ¢n tÃ­ch nÃ y.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./images/chapter_02_figure_02.png\" alt=\"image\" />\n",
    "</div>\n",
    "\n",
    "Má»™t trong nhá»¯ng loáº¡i **span** há»¯u Ã­ch lÃ  **named entity** ğŸ·ï¸. **Named entity** lÃ  má»™t chuá»—i kÃ½ tá»± Ä‘áº¡i diá»‡n cho cÃ¡c Ä‘á»‘i tÆ°á»£ng thá»±c táº¿, cháº³ng háº¡n nhÆ° con ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm, tá»• chá»©c, tÃªn thuá»‘c, v.v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marry: NP\n",
      "the green witch: NP\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Marry slapped the green witch.\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(f\"{chunk}: {chunk.label_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Structure of Sentences** ğŸ—ï¸ğŸ“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong khi **shallow parsing** lÃ  tÃ¡c vá»¥ xÃ¡c Ä‘á»‹nh cÃ¡c **cá»¥m tá»«**, thÃ¬ viá»‡c xÃ¡c Ä‘á»‹nh má»‘i liÃªn há»‡ giá»¯a cÃ¡c cá»¥m tá»« Ä‘Æ°á»£c gá»i lÃ  **parsing**. ğŸ“š\n",
    "\n",
    "CÃ³ hai cÃ¡ch phá»• biáº¿n Ä‘á»ƒ biá»ƒu diá»…n má»‘i quan há»‡ nÃ y:\n",
    "\n",
    "- **Constituent Parsing** ğŸ—ï¸: CÃ¡c thÃ nh pháº§n liÃªn káº¿t vá»›i nhau theo cáº¥u trÃºc phÃ¢n cáº¥p, giÃºp biá»ƒu diá»…n má»‘i quan há»‡ giá»¯a cÃ¡c cá»¥m tá»« trong cÃ¢u.\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./images/chapter_02_figure_03.png\" alt=\"image\" />\n",
    "</div>\n",
    "\n",
    "- **Dependency Parsing** ğŸ”—: Má»™t cÃ¡ch khÃ¡c Ä‘á»ƒ biá»ƒu diá»…n cÃ¡c má»‘i quan há»‡ lÃ  phÃ¢n tÃ­ch phá»¥ thuá»™c, trong Ä‘Ã³ má»—i tá»« phá»¥ thuá»™c vÃ o tá»« khÃ¡c trong cÃ¢u.\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./images/chapter_02_figure_04.png\" alt=\"image\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Word Senses and Semantic** ğŸ§ ğŸ”¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Má»™t tá»« cÃ³ thá»ƒ cÃ³ nhiá»u hÆ¡n má»™t nghÄ©a, vÃ  nhá»¯ng nghÄ©a khÃ¡c nhau cá»§a má»™t tá»« Ä‘Æ°á»£c gá»i lÃ  **senses** ğŸ§ . Tá»« ngá»¯ thÆ°á»ng mang nhiá»u **ngá»¯ nghÄ©a** vÃ  sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c nghÄ©a nÃ y giÃºp xÃ¡c Ä‘á»‹nh cÃ¡ch sá»­ dá»¥ng cá»§a tá»« trong cÃ¡c ngá»¯ cáº£nh khÃ¡c nhau. **WordNet** ğŸ“–, má»™t dá»± Ã¡n tÃ i nguyÃªn tá»« vá»±ng ná»•i tiáº¿ng cá»§a Äáº¡i há»c Princeton, má»¥c tiÃªu láº­p danh má»¥c cÃ¡c ngá»¯ nghÄ©a cá»§a háº§u háº¿t cÃ¡c tá»« trong tiáº¿ng Anh, cÃ¹ng vá»›i cÃ¡c má»‘i quan há»‡ tá»« vá»±ng khÃ¡c giá»¯a chÃºng.\n",
    "\n",
    "**VÃ­ dá»¥**, tá»« \"plane\" cÃ³ thá»ƒ cÃ³ nhiá»u nghÄ©a khÃ¡c nhau trong cÃ¡c ngá»¯ cáº£nh khÃ¡c nhau.\n",
    "\n",
    "Nhá»¯ng tháº­p ká»· nghiÃªn cá»©u vÃ  ná»— lá»±c trong cÃ¡c dá»± Ã¡n nhÆ° **WordNet** ráº¥t Ä‘Ã¡ng Ä‘á»ƒ báº¡n táº­n dá»¥ng, ngay cáº£ khi hiá»‡n nay cÃ³ sá»± xuáº¥t hiá»‡n cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n Ä‘áº¡i ğŸŒ.\n",
    "\n",
    "NgoÃ i ra, cÃ¡c **ngá»¯ nghÄ©a** cá»§a tá»« cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c suy ra tá»« **ngá»¯ cáº£nh** ğŸ“. Viá»‡c tá»± Ä‘á»™ng khÃ¡m phÃ¡ cÃ¡c ngá»¯ nghÄ©a tá»« vÄƒn báº£n thá»±c táº¿ lÃ  nÆ¡i há»c bÃ¡n giÃ¡m sÃ¡t (**semi-supervised learning**) láº§n Ä‘áº§u tiÃªn Ä‘Æ°á»£c á»©ng dá»¥ng trong NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./images/chapter_02_figure_05.png\" alt=\"image\" />\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factorial_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
